# ğŸ” Data Quality Monitoring - Implementation Guide

## âœ… **What I Built for You**

A comprehensive **Data Quality Monitoring Dashboard** that automatically checks data quality across all layers (Bronze, Silver, Gold) of your insurance analytics platform!

**Location:** `/Workspace/Shared/insurance-analytics/analytics/data_quality_monitoring`

---

## ğŸ¯ **What It Does**

### **Automated Quality Checks:**

1. **Null Rate Checks** âœ…
   - Monitors % of null values in each column
   - Threshold: 5% max (configurable)
   - Alerts when exceeded

2. **Duplicate Detection** âœ…
   - Finds duplicate records based on key columns
   - Threshold: 1% max duplicates
   - Ensures data uniqueness

3. **Freshness Monitoring** âœ…
   - Checks how old your data is
   - Threshold: 48 hours max
   - Critical for predictions!

4. **Row Count Validation** âœ…
   - Ensures minimum row counts
   - Detects pipeline failures
   - Tracks data volume trends

5. **Value Range Checks** âœ…
   - Validates numeric values are in expected ranges
   - Example: Age between 18-120
   - Catches data errors

---

## ğŸ“Š **What You'll See**

### **1. Overall Health Dashboard**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Data Quality Report                          â”‚
â”‚ Environment: DEV | Run Time: 2024-10-12 15:30  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚ Overall Pass Rate                               â”‚
â”‚        95.8%                                    â”‚
â”‚    205 / 214 checks passed                     â”‚
â”‚                                                 â”‚
â”‚ Total Checks: 214                               â”‚
â”‚ Failed Checks: 9 âš ï¸                             â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **2. Failed Checks Summary**
```
ğŸš¨ FAILED CHECKS - IMMEDIATE ATTENTION REQUIRED:

âš ï¸  HIGH NULL RATES (3 columns):
  â€¢ silver.customer_dim.email: 8.2% nulls
  â€¢ silver.policy_dim.agent_id: 6.1% nulls
  â€¢ gold.fraud_alerts.siu_notes: 12.3% nulls

ğŸš¨ STALE DATA (1 table):
  â€¢ gold.customer_churn_risk: 52.3 hours old
```

### **3. Interactive Charts**
- Null rate by layer (bar chart)
- Row counts by table (grouped bar chart)
- Data freshness timeline (with threshold line)

### **4. Trend Tracking**
- Historical metrics saved to `data_quality.quality_metrics_history`
- Track quality over time
- Identify deteriorating trends

---

## ğŸš€ **How to Use**

### **Step 1: Open the Notebook**
```
/Workspace/Shared/insurance-analytics/analytics/data_quality_monitoring
```

### **Step 2: Select Environment**
```
ğŸ“Š Environment Catalog: [insurance_dev_gold â–¼]
```
Options: dev, staging, or prod

### **Step 3: Run All**
- Click "Run All"
- Wait 2-5 minutes (depends on data volume)
- Review results!

### **Step 4: Take Action**
- Review any failed checks
- Investigate root causes
- Fix data quality issues
- Re-run affected ML predictions

---

## ğŸ” **Checks by Layer**

### **Bronze Layer (Raw Data)**
**Tables Checked:**
- `customers.customer_raw`
- `policies.policy_raw`
- `claims.claim_raw`

**Checks:**
- âœ… Null rates per column
- âœ… Duplicate records (by ID)
- âœ… Data freshness (timestamp)
- âœ… Minimum row count

**Why:** Catch ingestion issues early

---

### **Silver Layer (Cleaned Data)**
**Tables Checked:**
- `customers.customer_dim`
- `policies.policy_dim`
- `claims.claim_fact`

**Checks:**
- âœ… All Bronze checks
- âœ… Value range validation:
  - Age: 18-120 years
  - Premium: $100-$100,000
  - Coverage: $1,000-$10,000,000

**Why:** Ensure transformation quality

---

### **Gold Layer (Predictions)** ğŸ”¥
**Tables Checked:**
- `predictions.customer_churn_risk`
- `predictions.fraud_alerts`
- `predictions.claim_forecast`
- `predictions.premium_optimization`

**Checks:**
- âœ… All previous checks
- âœ… Prediction value ranges:
  - Churn probability: 0-1 (0-100%)
  - Fraud score: 0-100
  - Claim counts: 0-10,000
- âœ… **Freshness (CRITICAL!)**

**Why:** Invalid predictions = bad business decisions!

---

## âš™ï¸ **Configuration**

### **Thresholds (Customizable)**
```python
THRESHOLDS = {
    'null_rate': 0.05,          # Max 5% nulls
    'duplicate_rate': 0.01,     # Max 1% duplicates
    'freshness_hours': 48,      # Max 48 hours old
    'min_row_count': 100,       # Min 100 rows
}
```

**To change:**
1. Edit the THRESHOLDS dictionary in the notebook
2. Adjust based on your business requirements
3. Save and re-run

---

### **Range Checks (Customizable)**
```python
'range_checks': {
    'age_years': (18, 120),         # Valid age range
    'annual_premium': (100, 100000), # Valid premium range
}
```

**To add more:**
1. Add to the table config
2. Specify (min_value, max_value)
3. Run monitoring

---

## ğŸ“ˆ **Understanding Results**

### **Pass Rates:**
```
âœ… 90-100%  = GOOD     (healthy system)
âš ï¸  70-90%  = FAIR     (needs attention)
ğŸš¨ < 70%    = POOR     (critical issues)
```

### **Status Codes:**
```
PASS    âœ… Check passed
FAIL    âš ï¸  Check failed (action needed)
WARNING âš ï¸  Potential issue
SKIP    âšª Check not applicable
ERROR   âŒ Check couldn't run
```

### **Common Issues:**

**High Null Rates:**
- **Cause:** Missing data at source
- **Impact:** Incomplete analysis
- **Fix:** Investigate data pipeline

**Duplicates:**
- **Cause:** Deduplication logic issues
- **Impact:** Inflated metrics
- **Fix:** Review merge logic

**Stale Data:**
- **Cause:** Pipeline not running
- **Impact:** Outdated predictions
- **Fix:** Check job schedule

**Out of Range Values:**
- **Cause:** Data validation missing
- **Impact:** Invalid predictions
- **Fix:** Add validation rules

---

## ğŸš¨ **Alerting**

### **Current Implementation:**
```python
if failures:
    # Visual alert in notebook
    displayHTML(alert_message)
    
    # TODO: Send email/Slack notification
    # send_email(...)
    # send_slack_message(...)
```

### **To Enable Email Alerts:**
```python
# Add SMTP configuration
smtp_config = {
    'host': 'smtp.gmail.com',
    'port': 587,
    'username': 'your-email@company.com',
    'password': dbutils.secrets.get('email', 'smtp-password')
}

# Send alert
import smtplib
from email.mime.text import MIMEText

if failures:
    msg = MIMEText(alert_html, 'html')
    msg['Subject'] = f'ğŸš¨ DQ Alert: {len(failures)} failures in {env.upper()}'
    msg['From'] = smtp_config['username']
    msg['To'] = 'data-team@company.com'
    
    server = smtplib.SMTP(smtp_config['host'], smtp_config['port'])
    server.starttls()
    server.login(smtp_config['username'], smtp_config['password'])
    server.send_message(msg)
    server.quit()
```

---

## ğŸ“Š **Quality Metrics History**

### **Metrics Storage:**
All quality metrics are saved to:
```
{environment}_gold.data_quality.quality_metrics_history
```

**Schema:**
```sql
check_timestamp TIMESTAMP      -- When check ran
environment STRING             -- dev/staging/prod
layer STRING                   -- bronze/silver/gold
table_name STRING              -- Table checked
check_type STRING              -- null_rate, duplicate_rate, etc.
metric_name STRING             -- Column or metric name
metric_value DOUBLE            -- Numeric result
status STRING                  -- PASS/FAIL/WARNING
message STRING                 -- Details
```

**Benefits:**
- Track quality trends over time
- Identify deteriorating metrics
- Prove data quality SLAs
- Root cause analysis

---

## ğŸ“… **Scheduling (Recommended)**

### **Option 1: Databricks Job**
1. Create new job in Databricks
2. Set schedule: Daily at 6 AM
3. Add notebook: `data_quality_monitoring`
4. Configure alerts on failure

### **Option 2: Manual Trigger**
- Run after each pipeline execution
- Run before generating reports
- Run on demand when issues suspected

### **Option 3: Workflow Integration**
```python
# In your pipeline notebook
dbutils.notebook.run(
    "/Workspace/Shared/insurance-analytics/analytics/data_quality_monitoring",
    timeout_seconds=600,
    arguments={"environment_catalog": "insurance_dev_gold"}
)
```

---

## ğŸ¯ **Best Practices**

### **1. Run Regularly** â°
- Daily for production
- After each data refresh
- Before critical reports

### **2. Act on Failures** ğŸš¨
- Don't ignore failed checks
- Investigate root causes
- Fix at source, not symptoms

### **3. Adjust Thresholds** âš™ï¸
- Start conservative
- Tune based on your data
- Document changes

### **4. Review Trends** ğŸ“ˆ
- Weekly trend review
- Identify patterns
- Proactive prevention

### **5. Document Issues** ğŸ“
- Keep failure log
- Track resolutions
- Share learnings

---

## ğŸ’¡ **Advanced Features**

### **1. Add Custom Checks**
```python
def check_business_rule(df, table_name, layer):
    """Custom: Policies must have coverage >= premium"""
    violations = df.filter(
        col("coverage_amount") < col("annual_premium")
    ).count()
    
    return {
        'layer': layer,
        'table': table_name,
        'violations': violations,
        'status': 'PASS' if violations == 0 else 'FAIL',
        'message': f'{violations} business rule violations'
    }
```

### **2. Add More Tables**
```python
# Add to bronze_tables dictionary
'payments.payment_raw': {
    'key_columns': ['payment_id'],
    'timestamp_column': 'payment_date'
}
```

### **3. Export Reports**
```python
# Export as HTML
html_report = generate_html_report(all_results)
dbutils.fs.put(f"/mnt/reports/dq_report_{datetime.now().date()}.html", html_report, overwrite=True)

# Export as CSV
all_null_checks.to_csv(f'/dbfs/tmp/null_checks_{datetime.now().date()}.csv', index=False)
```

---

## ğŸ”§ **Troubleshooting**

### **Issue: "Table not found"**
**Cause:** Table doesn't exist in environment  
**Fix:** Create table or remove from check list

### **Issue: "Column not found"**
**Cause:** Schema changed  
**Fix:** Update column names in checks

### **Issue: "Check takes too long"**
**Cause:** Large data volume  
**Fix:** Add sampling for large tables

### **Issue: "False positives"**
**Cause:** Thresholds too strict  
**Fix:** Adjust THRESHOLDS dictionary

---

## ğŸ“š **Summary**

### **What You Now Have:**

âœ… **Comprehensive DQ Monitoring**
- 5 types of quality checks
- All layers covered (bronze/silver/gold)
- Automatic pass/fail detection

âœ… **Visual Dashboard**
- Overall health score
- Failed checks summary
- Interactive charts
- Historical trending

âœ… **Alerting Ready**
- Visual alerts in notebook
- Alert message generation
- Ready for email/Slack integration

âœ… **Production Ready**
- Configurable thresholds
- Extensible design
- Metrics persistence
- Scheduling friendly

---

## ğŸ¯ **Next Steps**

1. **Try it now:**
   - Open the notebook
   - Run All
   - Review results

2. **Customize:**
   - Adjust thresholds
   - Add custom checks
   - Configure alerts

3. **Schedule:**
   - Set up daily job
   - Configure notifications
   - Monitor trends

4. **Improve:**
   - Fix failed checks
   - Add more tables
   - Refine thresholds

---

## ğŸ’ª **Impact**

**Before DQ Monitoring:**
- âŒ Silent data quality issues
- âŒ Bad predictions go unnoticed
- âŒ Manual spot checks only
- âŒ Reactive problem solving

**After DQ Monitoring:**
- âœ… Proactive issue detection
- âœ… Automated quality checks
- âœ… Trend analysis
- âœ… Improved data trust
- âœ… Better predictions

---

**Your data quality is now monitored 24/7!** ğŸ”ğŸ“Š

**Questions? Run the notebook and explore the results!** ğŸš€

